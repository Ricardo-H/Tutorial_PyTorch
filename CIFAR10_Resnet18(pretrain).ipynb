{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动下载一些必要库\n",
    "!pip install torch torchvision\n",
    "!pip install numpy matplotlib seaborn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# CIFAR-10 dataset 导入\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用torch函数加载数据集\n",
    "trainset = datasets.CIFAR10(root='/mnt/ssd/dataset_CIFAR-10', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试数据集\n",
    "testset = datasets.CIFAR10(root='/mnt/ssd/dataset_CIFAR-10/cifar-10-batches-py', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# CIFAR-10类别\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义模型-使用预训练模型resnet18在CIFAR-10上图像分类\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# 固定参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(512, 10)       # 修改全连接层的输出为10\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの学習\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    print('-'*5, 'Epoch [{}/{}] start'.format(i, epoch-1), '-'*5)\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.train()\n",
    "    for image, target in trainloader:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image).squeeze()\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = (output.argmax(dim=1) == target).float().mean()\n",
    "        epoch_accuracy += acc / len(trainloader)\n",
    "        epoch_loss += loss / len(trainloader)\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy=0\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        for image, target in testloader:\n",
    "\n",
    "            # 入力、正解を GPU へ移動\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            # モデルに入力を順伝播させ予測を出力\n",
    "            output = model(image).squeeze()\n",
    "\n",
    "            # 損失関数で予測と正解の誤差や精度を導出\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == target).float().mean()\n",
    "            epoch_val_accuracy += acc / len(testloader)\n",
    "            epoch_val_loss += loss / len(testloader)\n",
    "\n",
    "    print(f'epoch:{i+1}/{epoch}, train_loss:{epoch_loss:.2f}, train_acc:{epoch_accuracy:.2f}, '+\n",
    "          f'val_loss:{epoch_val_loss:.2f}, val_acc:{epoch_val_accuracy:.2f}')\n",
    "    train_loss_list.append(epoch_loss)\n",
    "    train_acc_list.append(epoch_accuracy)\n",
    "    val_loss_list.append(epoch_val_loss)\n",
    "    val_acc_list.append(epoch_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習曲線の描画\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "  train_acc2 = train_acc_list[i].cpu()\n",
    "  train_acc3 = train_acc2.clone().numpy()\n",
    "  train_acc.append(train_acc3)\n",
    "\n",
    "  train_loss2 = train_loss_list[i].cpu()\n",
    "  train_loss3 = train_loss2.detach().numpy()\n",
    "  train_loss.append(train_loss3)\n",
    "\n",
    "  val_acc2 = val_acc_list[i].cpu()\n",
    "  val_acc3 = val_acc2.clone().numpy()\n",
    "  val_acc.append(val_acc3)\n",
    "\n",
    "  val_loss2 = val_loss_list[i].cpu()\n",
    "  val_loss3 = val_loss2.clone().numpy()\n",
    "  val_loss.append(val_loss3)\n",
    "\n",
    "\n",
    "#取得したデータをグラフ化する\n",
    "sns.set()\n",
    "num_epochs = epoch\n",
    "fig = plt.subplots(figsize=(12,4), dpi=80)\n",
    "\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.plot(range(num_epochs), train_acc, c='b', label='train acc')\n",
    "ax1.plot(range(num_epochs), val_acc, c='r', label='val acc')\n",
    "ax1.set_xlabel('epoch', fontsize='12')\n",
    "ax1.set_ylabel('accuracy', fontsize='12')\n",
    "ax1.set_title('training and val acc', fontsize='14')\n",
    "ax1.legend(fontsize='12')\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.plot(range(num_epochs), train_loss, c='b', label='train loss')\n",
    "ax2.plot(range(num_epochs), val_loss, c='r', label='val loss')\n",
    "ax2.set_xlabel('epoch', fontsize='12')\n",
    "ax2.set_ylabel('loss', fontsize='12')\n",
    "ax2.set_title('training and val loss', fontsize='14')\n",
    "ax2.legend(fontsize='12')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
