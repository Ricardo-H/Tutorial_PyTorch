{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动下载一些必要库\n",
    "!pip install torch torchvision\n",
    "!pip install numpy matplotlib seaborn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "# from tensorboardX import SummaryWriter  # 本code的tensorboard可视化方法都被注释掉了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载数据集 && 数据预处理\n",
    "这段code将CIFAR10的数据集下载在本地的`./data`文件夹下\n",
    "在这里我们使用了transforms模块对数据进行预处理，\n",
    "\n",
    "意义：对数据进行预处理，可以提高模型的泛化能力，同时也可以加快模型的训练速度，提高模型的精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# CIFAR-10 dataset 导入\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义CIFAR-10 数据集类\n",
    "用于读取数据集--CIFAR-10,并且对数据集进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "        # 根据训练或测试集加载不同的文件\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        if self.train:\n",
    "            for i in range(1, 6):\n",
    "                file = os.path.join(self.root_dir, 'data_batch_' + str(i))\n",
    "                with open(file, 'rb') as fo:\n",
    "                    dict = pickle.load(fo, encoding='bytes')\n",
    "                    self.data.append(dict[b'data'])\n",
    "                    self.labels += dict[b'labels']\n",
    "            self.data = torch.cat([torch.tensor(d).view(-1, 3, 32, 32) for d in self.data])\n",
    "        else:\n",
    "            file = os.path.join(self.root_dir, 'test_batch')\n",
    "            with open(file, 'rb') as fo:\n",
    "                dict = pickle.load(fo, encoding='bytes')\n",
    "                self.data = torch.tensor(dict[b'data']).view(-1, 3, 32, 32)\n",
    "                self.labels = dict[b'labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 将图像数据格式从[channels, height, width]转换为PIL图像格式\n",
    "        image = Image.fromarray(image.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 使用torch函数加载数据集\n",
    "#trainset = datasets.CIFAR10(root='/mnt/ssd/dataset_CIFAR-10', train=True, download=True, transform=transform)\n",
    "#  使用自定义的CIFAR10Dataset类加载数据集\n",
    "trainset = CIFAR10Dataset(root_dir='./data/cifar-10-batches-py/', train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载测试数据集\n",
    "#testset = datasets.CIFAR10(root='/mnt/ssd/dataset_CIFAR-10/cifar-10-batches-py', train=False, download=True, transform=transform)\n",
    "# 使用自定义的CIFAR10Dataset类加载数据集\n",
    "testset = CIFAR10Dataset(root_dir='./data/cifar-10-batches-py/', train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# CIFAR-10类别\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据集后(并且完成预处理了), \n",
    "#### 可视化一些训练样本(dataloader中的数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # 反标准化normalize\n",
    "    npimg = img.numpy()     # 将Tensor转换为ndarray\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # 转换为[height, width, channels]\n",
    "    plt.show()\n",
    "\n",
    "# 获取一些随机训练图片\n",
    "dataiter = iter(trainloader)    # 将trainloader转换为迭代器\n",
    "images, labels = next(dataiter) # 获取一组图像和标签\n",
    "\n",
    "# 显示批量图片\n",
    "imshow(torchvision.utils.make_grid(images)) # 将一个batch_size的图像拼接成网格\n",
    "print(','.join('%5s' % classes[labels[j]] for j in range(16)))\n",
    "\n",
    "'''\n",
    "# 显示一张图片与标签\n",
    "imshow(images[0])\n",
    "print(classes[labels[0]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单CNN模型--LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self): #定义了网络的结构\n",
    "        super(LeNet, self).__init__()\n",
    "        # 第一个卷积层: 输入通道数为3（对于RGB图像），输出通道数为6，卷积核大小为5x5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # 第二个卷积层: 输入通道数为6，输出通道数为16，卷积核大小为5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # 最大池化层，使用2x2窗口, 步长为2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 全连接层1: 输入特征数为16 * 6 * 6（16个通道，每个通道的大小是5x5），输出特征数为120\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)   # 5*5是通过计算得到的图像大小\n",
    "        # 全连接层2: 输入特征数为120，输出特征数为84\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 全连接层3（输出层）: 输入特征数为84，输出特征数为10（对应10个类别）\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):   #定义了数据通过网络的方式\n",
    "        # 应用第一个卷积层 followed by ReLU激活函数和池化\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # 应用第二个卷积层 followed by ReLU激活函数和池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # 展平所有除批次维度以外的维度\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        # 应用第一个全连接层和ReLU激活函数\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        # 应用第二个全连接层和ReLU激活函数\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 应用输出层\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义模型\n",
    "#model = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "model = LeNet()\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの学習\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "epoch = 10\n",
    "# 使用tensorboardX进行可视化\n",
    "#writer = SummaryWriter(comment='test_comment', filename_suffix=\"CIFAR10_Lenet\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print('-'*5, 'Epoch [{}/{}] start'.format(i, epoch-1), '-'*5)\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.train()\n",
    "    for image, target in tqdm(trainloader):\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image).squeeze()\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = (output.argmax(dim=1) == target).float().mean()\n",
    "        epoch_accuracy += acc / len(trainloader)\n",
    "        epoch_loss += loss / len(trainloader)\n",
    "        \n",
    "    # モデルの検証、評価モード切替\n",
    "    model.eval()\n",
    "\n",
    "    # 検証データのデータローダから読み込み尽くすまでループ\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy=0\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        for image, target in testloader:\n",
    "\n",
    "            # 入力、正解を GPU へ移動\n",
    "            image, target = image.cuda(), target.cuda()\n",
    "\n",
    "            # モデルに入力を順伝播させ予測を出力\n",
    "            output = model(image).squeeze()\n",
    "\n",
    "            # 損失関数で予測と正解の誤差や精度を導出\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == target).float().mean()\n",
    "            epoch_val_accuracy += acc / len(testloader)\n",
    "            epoch_val_loss += loss / len(testloader)\n",
    "\n",
    "    print('epoch',epoch)\n",
    "    print('acc',epoch_accuracy)\n",
    "    print('loss',epoch_loss)\n",
    "    print('val_acc',epoch_val_accuracy)\n",
    "    print('val_loss',epoch_val_loss)\n",
    "    train_loss_list.append(epoch_loss)\n",
    "    train_acc_list.append(epoch_accuracy)\n",
    "    val_loss_list.append(epoch_val_loss)\n",
    "    val_acc_list.append(epoch_val_accuracy)\n",
    "#     writer.add_scalar('train_loss', epoch_loss, i)\n",
    "#     writer.add_scalar('train_acc', epoch_accuracy, i)\n",
    "#     writer.add_scalar('val_loss', epoch_val_loss, i)\n",
    "#     writer.add_scalar('val_acc', epoch_val_accuracy, i)\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果可视化\n",
    "1. 训练集和验证集的accuracy曲线\n",
    "2. 训练集和验证集的loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習曲線の描画\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "  train_acc2 = train_acc_list[i].cpu()\n",
    "  train_acc3 = train_acc2.clone().numpy()\n",
    "  train_acc.append(train_acc3)\n",
    "\n",
    "  train_loss2 = train_loss_list[i].cpu()\n",
    "  train_loss3 = train_loss2.detach().numpy()\n",
    "  train_loss.append(train_loss3)\n",
    "\n",
    "  val_acc2 = val_acc_list[i].cpu()\n",
    "  val_acc3 = val_acc2.clone().numpy()\n",
    "  val_acc.append(val_acc3)\n",
    "\n",
    "  val_loss2 = val_loss_list[i].cpu()\n",
    "  val_loss3 = val_loss2.clone().numpy()\n",
    "  val_loss.append(val_loss3)\n",
    "\n",
    "\n",
    "#取得したデータをグラフ化する\n",
    "sns.set()\n",
    "num_epochs = epoch\n",
    "fig = plt.subplots(figsize=(12,4), dpi=80)\n",
    "\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.plot(range(num_epochs), train_acc, c='b', label='train acc')\n",
    "ax1.plot(range(num_epochs), val_acc, c='r', label='val acc')\n",
    "ax1.set_xlabel('epoch', fontsize='12')\n",
    "ax1.set_ylabel('accuracy', fontsize='12')\n",
    "ax1.set_title('training and val acc', fontsize='14')\n",
    "ax1.legend(fontsize='12')\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.plot(range(num_epochs), train_loss, c='b', label='train loss')\n",
    "ax2.plot(range(num_epochs), val_loss, c='r', label='val loss')\n",
    "ax2.set_xlabel('epoch', fontsize='12')\n",
    "ax2.set_ylabel('loss', fontsize='12')\n",
    "ax2.set_title('training and val loss', fontsize='14')\n",
    "ax2.legend(fontsize='12')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
